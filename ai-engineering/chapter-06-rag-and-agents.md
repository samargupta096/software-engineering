# Chapter 6: RAG and Agents

> *Extending model capabilities through retrieval and tool use*

---

## ğŸ¯ Core Concepts

### Part 1: Retrieval-Augmented Generation (RAG)

#### Why RAG?

- Models have **knowledge cutoff dates** â€” RAG provides fresh information
- Reduces **hallucinations** by grounding responses in actual documents
- Enables **domain-specific** knowledge without finetuning
- More **cost-effective** than finetuning for many use cases

#### RAG Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  User Query  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Embedding  â”‚
                    â”‚    Model     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚        Vector Store             â”‚
          â”‚  (Similarity Search / Hybrid)   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Top-K Docs  â”‚
                    â”‚  Retrieved   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Augmented Prompt           â”‚
              â”‚  = System + Context + Query â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     LLM      â”‚
                    â”‚   Response   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Key RAG Components

| Component | Options | Considerations |
|-----------|---------|----------------|
| **Chunking** | Fixed-size, semantic, sentence, recursive | Chunk size affects retrieval quality |
| **Embeddings** | OpenAI, Cohere, open-source | Dimension size, multilingual support |
| **Vector Store** | Pinecone, Weaviate, Chroma, pgvector | Scale, latency, cost |
| **Retrieval** | Dense, sparse (BM25), hybrid | Combine semantic + keyword search |
| **Reranking** | Cross-encoders, Cohere Rerank | Improves precision after retrieval |

#### RAG Strategies

- **Naive RAG**: Simple retrieve â†’ generate
- **Advanced RAG**: Query transformation, re-ranking, iterative retrieval
- **Modular RAG**: Composable retrieval pipelines
- **Multi-hop RAG**: Multiple retrieval steps for complex questions
- **Agentic RAG**: Agent decides when and how to retrieve

---

### Part 2: Agents

#### What is an Agent?

- An AI system that can **plan**, **reason**, and **take actions** using tools
- Goes beyond simple Q&A â€” can break down tasks and execute steps
- Uses the model as a **reasoning engine**, not just a text generator

#### Agent Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 AGENT                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Planning  â”‚â†’ â”‚ Reasoningâ”‚â†’ â”‚ Action â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚       â†‘              â†‘           â”‚       â”‚
â”‚       â”‚         â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”      â–¼       â”‚
â”‚       â”‚         â”‚ Memory  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚       â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ Tools  â”‚  â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”‚  â”‚
â”‚            Observation       â”‚ â€¢ Searchâ”‚  â”‚
â”‚                              â”‚ â€¢ Code  â”‚  â”‚
â”‚                              â”‚ â€¢ APIs  â”‚  â”‚
â”‚                              â”‚ â€¢ DB    â”‚  â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Agent Patterns

- **ReAct**: Reasoning + Acting alternating loop
- **Plan-and-Execute**: Plan all steps first, then execute
- **Tool Use**: Model decides which tools to call and with what params
- **Multi-Agent**: Multiple specialized agents collaborating

#### Evaluating Agents

- Task completion rate
- Number of steps / efficiency
- Tool usage accuracy
- Cost per task
- Failure mode analysis

---

## ğŸ“ My Notes

<!-- Add your own notes, insights, and questions as you read -->



---

## â“ Questions to Reflect On

1. When is RAG sufficient vs. when do you need finetuning?
2. How do you choose the right chunk size and overlap for your documents?
3. What makes agents reliable enough for production use?
4. How do you handle agent failures gracefully?

---

## ğŸ”— Key Takeaways

1. 
2. 
3. 

---

## ğŸ› ï¸ Practice Ideas

- [ ] Build a RAG pipeline with a small document set â€” measure retrieval quality
- [ ] Compare naive RAG vs. RAG with reranking on the same queries
- [ ] Build a simple agent with 2-3 tools (search, calculator, code exec)
- [ ] Evaluate agent performance: success rate, steps, cost analysis


---

<div align="center">

[â¬…ï¸ Previous Chapter](./chapter-05-prompt-engineering.md) | [ğŸ  Home](./README.md) | [Next Chapter â¡ï¸](./chapter-07-finetuning.md)

</div>
